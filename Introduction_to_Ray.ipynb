{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praveen76/Introduction-to-RAY/blob/main/Introduction_to_Ray.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imported-begin"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "solid-upset"
      },
      "source": [
        "At the end of the experiment, you will be able to:\n",
        "\n",
        "* load the data into RayDMatrix\n",
        "* train the XGBoost Ray model and save it\n",
        "* tune the Hyperparameters using Ray tune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8newvEJqhW0"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Compute demands for machine learning (ML) training have grown 10x every\n",
        "18 months since 2010. Over the same time period, the compute capabilities of\n",
        "AI accelerators such as GPUs and TPUs have less than doubled. This means\n",
        "that every year and a half organizations need 5x more AI accelerators/nodes\n",
        "to train the latest ML models and leverage cutting edge ML capabilities.\n",
        "Distributed computing is the only way to meet these requirements.\n",
        "\n",
        "While solutions such as AWS SageMaker and GCP Vertex AI have emerged\n",
        "to help organizations deal with scaling AI workloads, these solutions put\n",
        "significant constraints on how applications are developed and which libraries\n",
        "they can use. This makes it difficult to keep up with the latest models and\n",
        "algorithms, and freely integrate with the rapidly evolving open ML ecosystem.\n",
        "\n",
        "Ray, addresses these challenges head on by\n",
        "allowing ML engineers and developers to scale their workloads effortlessly\n",
        "from their laptops to the cloud without the need to build complex compute\n",
        "infrastructures."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <img src='https://global.discourse-cdn.com/business7/uploads/ray/original/1X/8f4dcb72f7cd34e2a332d548bd65860994bc8ff1.png' width=20px> **Ray**\n",
        "\n",
        "Ray is an open-source unified framework for scaling AI and Python applications like machine learning. It provides the compute layer for parallel processing and reduce the need of a distributed systems expert. Ray minimizes the complexity of running your distributed individual and end-to-end machine learning workflows with these components:\n",
        "\n",
        "- Scalable libraries for common machine learning tasks such as data preprocessing, distributed training, hyperparameter tuning, reinforcement learning, and model serving.\n",
        "\n",
        "- Pythonic distributed computing primitives for parallelizing and scaling Python applications.\n",
        "\n",
        "- Integrations and utilities for integrating and deploying a Ray cluster with existing tools and infrastructure such as Kubernetes, AWS, GCP, and Azure.\n",
        "<br>\n",
        "\n",
        "Some common ML workloads that individuals, organizations, and companies leverage Ray to build their AI applications include:\n",
        "\n",
        "- Batch inference on CPUs and GPUs\n",
        "- Parallel training\n",
        "- Model serving\n",
        "- Distributed training of large models\n",
        "- Parallel hyperparameter tuning experiments\n",
        "- Reinforcement learning\n",
        "- ML platform\n"
      ],
      "metadata": {
        "id": "5LOtZlckE1vW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ray framework**\n",
        "\n",
        "<center>\n",
        "<img src=\"https://cdn.iisc.talentsprint.com/AIandMLOps/Images/Ray_framework.png\" width=500px></center>\n",
        "<br><br>\n",
        "\n",
        "Ray's unified compute framework consists of three layers:\n",
        "\n",
        "- ***Ray AI Libraries:*** An open-source, Python, domain-specific set of libraries that equip ML engineers, data scientists, and researchers with a scalable and unified toolkit for ML applications.\n",
        "\n",
        "- ***Ray Core:*** An open-source, Python, general purpose, distributed computing library that enables ML engineers and Python developers to scale Python applications and accelerate machine learning workloads.\n",
        "\n",
        "- ***Ray Clusters:*** A set of worker nodes connected to a common Ray head node. Ray clusters can be fixed-size, or they can autoscale up and down according to the resources requested by applications running on the cluster.\n",
        "\n",
        "<br>\n",
        "\n",
        "Each of Ray's five native libraries distributes a specific ML task:\n",
        "\n",
        "- **`Data`**: Scalable, framework-agnostic data loading and transformation across training, tuning, and prediction\n",
        "\n",
        "- **`Train`**: Distributed multi-node and multi-core model training with fault tolerance that integrates with popular training libraries\n",
        "\n",
        "- **`Tune`**: Scalable hyperparameter tuning to optimize model performance\n",
        "\n",
        "- **`Serve`**: Scalable and programmable serving to deploy models for online inference, with optional microbatching to improve performance\n",
        "\n",
        "- **`RLlib`**: Scalable distributed reinforcement learning workloads\n"
      ],
      "metadata": {
        "id": "HfJAEecJHefq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOno0OCY5KSD"
      },
      "source": [
        "Find the official Ray website [here](https://www.ray.io/), and its documentation [here](https://docs.ray.io/en/latest/ray-overview/index.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8ZyR1qqtr6_"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YzfoPvJDiTX"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjoZJWGErxGf"
      },
      "source": [
        "#@title Please enter your password (your registered phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBPPuGmBlDIN",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"M8_AST_05_Distributed_XGBoost_with_Ray_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://aimlops-iisc.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmE9xB1w4K8M"
      },
      "source": [
        "### Install necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXbmHKD_JBsx"
      },
      "outputs": [],
      "source": [
        "!pip -q install ray\n",
        "!pip -q install ray[tune]\n",
        "!pip -q install xgboost_ray"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3600ee25c8e"
      },
      "source": [
        "### Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMFdp-Bw4leX"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost_ray import RayDMatrix, RayParams, train, predict\n",
        "\n",
        "from ray import tune\n",
        "from ray import train as raytrain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRY_jIUFZtt7"
      },
      "source": [
        "### Load the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, train_y = load_breast_cancer(return_X_y=True)\n",
        "train_x.shape, train_y.shape"
      ],
      "metadata": {
        "id": "AsZa7JUJbSFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x"
      ],
      "metadata": {
        "id": "hWRH1L0YbIjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y"
      ],
      "metadata": {
        "id": "ctbE_KGJbP7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuMogwjLuj5-"
      },
      "source": [
        "### XGBoost-Ray uses the same API as core XGBoost\n",
        "\n",
        "There are only two differences:\n",
        "\n",
        "* Instead of using a `xgboost.DMatrix`, it uses `xgboost_ray.RayDMatrix` object\n",
        "\n",
        "* There is an additional `ray_params` parameter that is used to configure distributed training (it takes a `RayParams` object)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data loading**\n",
        "\n",
        "Data is passed to XGBoost-Ray via a `RayDMatrix` object.\n",
        "\n",
        "The `RayDMatrix` lazy loads data and stores it sharded in the Ray object store. The Ray XGBoost actors then access these shards to run their training on.\n",
        "\n",
        "A `RayDMatrix` support various data and file types, like Pandas DataFrames, Numpy Arrays, CSV files and Parquet files."
      ],
      "metadata": {
        "id": "2RBrYsE3a-HM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaoyQ7TburU0"
      },
      "outputs": [],
      "source": [
        "train_set = RayDMatrix(train_x, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ray_params = RayParams(num_actors = 2,               # Number of remote actors\n",
        "                       cpus_per_actor = 1\n",
        "                       )"
      ],
      "metadata": {
        "id": "fJ8q7pnAsJdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4WIhjlj2oT_"
      },
      "source": [
        "### Train the XGBoost Ray model and save it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06u-IMu1I0c_"
      },
      "outputs": [],
      "source": [
        "evals_result = {}\n",
        "bst = train(\n",
        "    params={\n",
        "        \"objective\": \"binary:logistic\",                # tells XGBoost that we aim to train a logistic regression model for a binary classification task\n",
        "        \"eval_metric\": [\"logloss\", \"error\"],\n",
        "    },\n",
        "    dtrain=train_set,\n",
        "    evals_result=evals_result,\n",
        "    evals=[(train_set, \"train\")],\n",
        "    verbose_eval=False,\n",
        "    ray_params=ray_params)\n",
        "\n",
        "bst.save_model(\"model.xgb\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_brYTFg2tZs"
      },
      "source": [
        "### Final training error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5dTgkUZ2Zcn"
      },
      "outputs": [],
      "source": [
        "print(\"Final training error: {:.4f}\".format(evals_result[\"train\"][\"error\"][-1]))\n",
        "print(\"Final training accuracy: {:.4f}\".format(1 - evals_result[\"train\"][\"error\"][-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c01Q3syvz66n"
      },
      "source": [
        "### Prediction\n",
        "\n",
        "Here, we will create an object of regular non-distributed API instance i.e. `xgboost.Booster`, and pass the saved XGBoost-Ray model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkJFmGsZJKCu"
      },
      "outputs": [],
      "source": [
        "dpred = RayDMatrix(train_x, train_y)\n",
        "\n",
        "bst = xgb.Booster(model_file=\"model.xgb\")                    # non-distributed XGBoost API instance\n",
        "\n",
        "pred_ray = predict(bst,\n",
        "                   dpred,\n",
        "                   ray_params = RayParams(num_actors=2)      # The data will be split across two actors. The result array will integrate this data in the correct order.\n",
        "                   )\n",
        "\n",
        "print(pred_ray)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model output to labels\n",
        "prediction = [int(i > 0.5) for i in pred_ray]\n",
        "print(prediction)"
      ],
      "metadata": {
        "id": "CtHSvCYRe-G0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(prediction, train_y)"
      ],
      "metadata": {
        "id": "jt9n5T63fOjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9E6n1LzUsnld"
      },
      "source": [
        "## Hyperparameter Tuning with Ray Tune"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By using tuning libraries such as **Ray Tune** we can try out combinations of hyperparameters. Using sophisticated search strategies, these parameters can be selected so that they are likely to lead to good results (avoiding an expensive exhaustive search).\n",
        "\n",
        "Also, trials that do not perform well can be preemptively stopped to reduce waste of computing resources. Ray Tune also takes care of training these runs in parallel, greatly increasing search speed."
      ],
      "metadata": {
        "id": "j8sWIT0QjJBL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzt3PmB94KyN"
      },
      "source": [
        "**Steps:**\n",
        "1. Put the non-distributed XGBoost training call into a function accepting parameter configurations (`train_breast_cancer_model()` in the example below)\n",
        "\n",
        "2. Define the parameter search space (`config` dictionary)\n",
        "\n",
        "3. Create `tune.Tuner()` object:\n",
        "    * pass training call function\n",
        "    * pass tuning configuration `tune.TuneConfig()`\n",
        "        * `num_samples`: number of different hyperparameter configurations from the search space\n",
        "        * `metric`: the metric to optimized\n",
        "        * `mode`: should either be min or max, depending on whether the metric is to be minimized or maximized\n",
        "    * pass parameter search space\n",
        "\n",
        "4. Call `tuner.fit()`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for XGBoost training\n",
        "def train_breast_cancer_model(config):\n",
        "    # Load dataset\n",
        "    data, labels = load_breast_cancer(return_X_y=True)\n",
        "    # Split into train and test set\n",
        "    train_x, test_x, train_y, test_y = train_test_split(data, labels, test_size=0.25)\n",
        "\n",
        "    # Build input matrices for XGBoost\n",
        "    train_set = xgb.DMatrix(train_x, label=train_y)\n",
        "    test_set = xgb.DMatrix(test_x, label=test_y)\n",
        "\n",
        "    # Train the classifier\n",
        "    results = {}\n",
        "    xgb.train(\n",
        "        params=config,\n",
        "        dtrain=train_set,\n",
        "        evals=[(test_set, \"eval\")],\n",
        "        evals_result=results,\n",
        "        verbose_eval=False,\n",
        "    )\n",
        "    # Return prediction accuracy\n",
        "    accuracy = 1.0 - results[\"eval\"][\"error\"][-1]\n",
        "    raytrain.report({\"mean_accuracy\": accuracy, \"done\": True})        #  instead of returning the accuracy value, we report it back to Tune using session.report()\n",
        "\n",
        "\n",
        "# Define the parameter search space\n",
        "config = {\n",
        "    \"objective\": \"binary:logistic\",                            # tells XGBoost that we aim to train a logistic regression model for a binary classification task\n",
        "    \"eval_metric\": [\"logloss\", \"error\"],\n",
        "    \"max_depth\": tune.randint(1, 9),                           # hyperparameter    'tune.randint(min, max)' chooses a random integer value between min and max\n",
        "    \"min_child_weight\": tune.choice([1, 2, 3]),                # hyperparameter    'tune.choice([a, b, c])' chooses one of the items of the list at random\n",
        "    \"subsample\": tune.uniform(0.5, 1.0),                       # hyperparameter    'tune.uniform(min, max)' samples a floating point number between min and max\n",
        "    \"eta\": tune.loguniform(1e-4, 1e-1),                        # hyperparameter    'tune.loguniform(min, max, base=10)' samples a floating point number between min and max,\n",
        "                                                               #                    but applies a logarithmic transformation to these boundaries first\n",
        "    }\n",
        "\n",
        "tuner = tune.Tuner(\n",
        "    train_breast_cancer_model,\n",
        "    tune_config = tune.TuneConfig(num_samples=10,              # sample 10 different hyperparameter configurations from the search space\n",
        "                                  metric=\"mean_accuracy\",      # the metric to optimized\n",
        "                                  mode=\"max\"                   # the mode should either be min or max, depending on whether the metric is to be minimized or maximized\n",
        "                                  ),\n",
        "    param_space = config                                       # parameter search space\n",
        ")\n",
        "\n",
        "results = tuner.fit()"
      ],
      "metadata": {
        "id": "pgSlp5jN5e3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best hyperparameters\n",
        "best_params = results.get_best_result().config\n",
        "best_params"
      ],
      "metadata": {
        "id": "4l4i2xW95_cv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All trial results\n",
        "df = results.get_dataframe()\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "4kBwfVoR6w3h"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}